{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Cognitive Service Vision Product Recognition using Python\n",
    "\n",
    "This is a tutorial about using Cognitive Service Vision Model Product Recognition\n",
    "\n",
    "Currently, product recognition feature are available in **EastUS**, **West US2**, and **West Europe** regions.\n",
    "\n",
    "Please create a computer vision resource on Azure portal, in **EastUS**, **West US2**, or **West Europe** region, if you don't already have one. You can use [Multi-service resource](https://learn.microsoft.com/en-us/azure/cognitive-services/cognitive-services-apis-create-account?tabs=multiservice%2Canomaly-detector%2Clanguage-service%2Ccomputer-vision%2Cwindows) as well. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the python samples package\n",
    "\n",
    "Install the sample code including utility code helping you use Python to:\n",
    "- Pre-process your image such as image stitching and image rectification before doing product recognition and planogram compliance\n",
    "- Run product recognition pre-built model\n",
    "- Run planogram compliance checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cognitive-service-vision-model-customization-python-samples in d:\\miniconda3\\envs\\pytorch\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: requests in d:\\miniconda3\\envs\\pytorch\\lib\\site-packages (from cognitive-service-vision-model-customization-python-samples) (2.27.1)\n",
      "Requirement already satisfied: tqdm in d:\\miniconda3\\envs\\pytorch\\lib\\site-packages (from cognitive-service-vision-model-customization-python-samples) (4.63.0)\n",
      "Requirement already satisfied: azure-storage-blob in d:\\miniconda3\\envs\\pytorch\\lib\\site-packages (from cognitive-service-vision-model-customization-python-samples) (12.13.1)\n",
      "Requirement already satisfied: azure-cognitiveservices-vision-customvision in d:\\miniconda3\\envs\\pytorch\\lib\\site-packages (from cognitive-service-vision-model-customization-python-samples) (3.1.0)\n",
      "Requirement already satisfied: cffi in d:\\miniconda3\\envs\\pytorch\\lib\\site-packages (from cognitive-service-vision-model-customization-python-samples) (1.15.0)\n",
      "Requirement already satisfied: msrest>=0.5.0 in d:\\miniconda3\\envs\\pytorch\\lib\\site-packages (from azure-cognitiveservices-vision-customvision->cognitive-service-vision-model-customization-python-samples) (0.7.1)\n",
      "Requirement already satisfied: azure-common~=1.1 in d:\\miniconda3\\envs\\pytorch\\lib\\site-packages (from azure-cognitiveservices-vision-customvision->cognitive-service-vision-model-customization-python-samples) (1.1.28)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.23.1 in d:\\miniconda3\\envs\\pytorch\\lib\\site-packages (from azure-storage-blob->cognitive-service-vision-model-customization-python-samples) (1.26.0)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in d:\\miniconda3\\envs\\pytorch\\lib\\site-packages (from azure-storage-blob->cognitive-service-vision-model-customization-python-samples) (36.0.0)\n",
      "Requirement already satisfied: pycparser in d:\\miniconda3\\envs\\pytorch\\lib\\site-packages (from cffi->cognitive-service-vision-model-customization-python-samples) (2.21)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\miniconda3\\envs\\pytorch\\lib\\site-packages (from requests->cognitive-service-vision-model-customization-python-samples) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\miniconda3\\envs\\pytorch\\lib\\site-packages (from requests->cognitive-service-vision-model-customization-python-samples) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\miniconda3\\envs\\pytorch\\lib\\site-packages (from requests->cognitive-service-vision-model-customization-python-samples) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\miniconda3\\envs\\pytorch\\lib\\site-packages (from requests->cognitive-service-vision-model-customization-python-samples) (3.3)\n",
      "Requirement already satisfied: colorama in d:\\miniconda3\\envs\\pytorch\\lib\\site-packages (from tqdm->cognitive-service-vision-model-customization-python-samples) (0.4.5)\n",
      "Requirement already satisfied: six>=1.11.0 in d:\\miniconda3\\envs\\pytorch\\lib\\site-packages (from azure-core<2.0.0,>=1.23.1->azure-storage-blob->cognitive-service-vision-model-customization-python-samples) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in d:\\miniconda3\\envs\\pytorch\\lib\\site-packages (from azure-core<2.0.0,>=1.23.1->azure-storage-blob->cognitive-service-vision-model-customization-python-samples) (4.4.0)\n",
      "Requirement already satisfied: isodate>=0.6.0 in d:\\miniconda3\\envs\\pytorch\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-customvision->cognitive-service-vision-model-customization-python-samples) (0.6.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in d:\\miniconda3\\envs\\pytorch\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-customvision->cognitive-service-vision-model-customization-python-samples) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\miniconda3\\envs\\pytorch\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.0->azure-cognitiveservices-vision-customvision->cognitive-service-vision-model-customization-python-samples) (3.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cognitive-service-vision-product-recogntion-python-samples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credentials\n",
    "\n",
    "Resource name and resource key are needed for accessing the service, which you can find here:\n",
    "\n",
    "![check media/credentials.png if pic does not show up](./media/credentials.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resource and key\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "from cognitive_service_vision_model_customization_python_samples import ResourceType\n",
    "\n",
    "resource_type = ResourceType.SINGLE_SERVICE_RESOURCE # or ResourceType.MULTI_SERVICE_RESOURCE\n",
    "\n",
    "resource_name = None\n",
    "multi_service_endpoint = None\n",
    "\n",
    "if resource_type == ResourceType.SINGLE_SERVICE_RESOURCE:\n",
    "    resource_name = '{specify_your_resource_name}'\n",
    "    assert resource_name\n",
    "else:\n",
    "    multi_service_endpoint = '{specify_your_service_endpoint}'\n",
    "    assert multi_service_endpoint\n",
    "\n",
    "resource_key = '{specify_your_resource_key}'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run product recognition on prebuilt model\n",
    "\n",
    "You can run product recognition to detect products and gaps using our prebuilt model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognitive_service_vision_product_recognition_python_samples import ProductRecognitionClient\n",
    "product_recognition_client = ProductRecognitionClient(resource_type, resource_name, multi_service_endpoint, resource_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite\n",
    "\n",
    "Follow the Cognitive Service Vision Model Customization document to train a customized product recognition model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
